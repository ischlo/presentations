{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Downscaling Global Economic Activity Data : A Spatial and Sectorial perspective using Bayesian Hierarchical Modelling\"\n",
        "format: \n",
        "    revealjs:\n",
        "        theme: [\"./pres_style.scss\",default]\n",
        "    # pdf : default\n",
        "    # beamer\n",
        "author:\n",
        "  - name: Ivann Schlosser\n",
        "    email: ivann.schlosser@ouce.ox.co.uk\n",
        "    url: ischlosser.com\n",
        "    affiliations:\n",
        "      - name: Oxford Progamme for Sustainable Infrastructure Systems (OPSIS)\n",
        "        address: South Parks Road\n",
        "        postal-code: OX1 3QY\n",
        "        city: Oxford\n",
        "# bibliography: references.bib\n",
        "---\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "## Glossary\n",
        "\n",
        "**BHM** - Bayesian Hierarchical Model\n",
        "\n",
        "**MCMC** - Markov Chain Monte Carlo\n",
        "\n",
        "**Marginal Probability** - probability of a single variable\n",
        "\n",
        "## Where we left off\n",
        "\n",
        "- Pycnophylactic condition\n",
        "- Rescaling, using Overture POIs and their categories as source for density distribution of activity on the ground.\n",
        "\n",
        "### Pros\n",
        "\n",
        "- Simple\n",
        "- Efficient\n",
        "- Global\n",
        "\n",
        "### Cons\n",
        "\n",
        "- Did not use additional available information : sector level data, regional accounts from local sources, other global layers such as population, Non-Residential built infrastructure etc...\n",
        "- Univariate model\n",
        "- Hard constraint\n",
        "- No flexibility\n",
        "\n",
        "## Can we do better ?\n",
        "\n",
        "**YES**, but at a bigger cost.\n",
        "\n",
        "However, it allows us to answer all off the previous cons, while preserving the pros.\n",
        "\n",
        "The methodology was significantly expanded to use Bayesian Hierarchical Modelling (BHM).\n",
        "\n",
        "\n",
        "##Â Methods\n",
        "\n",
        "### BHM in 2 slides\n",
        "\n",
        "As the name suggests, at the centre of this method relies the well familiar Bayes rule. \n",
        "Let us remind ourselves. If we have two random variables (RV), and we are modelling them together, we might find ourselves asking questions of the nature :\n",
        "\n",
        "> What is the probability of a joint event, or a conditional event, having observed only the outcome of a single one ?\n",
        "\n",
        "This, in practice, takes the form $p(x,z)$. And in such cases, Bayes rule tells us that \n",
        "$$\n",
        "p(x,z) = p(z) * p(x|z) \\\\\n",
        "p(x,z) = p(x) * p(z|x)\n",
        "$$\n",
        "\n",
        " <!-- \"What is the probability of observing $x$, having already observed $z$ ?\"\n",
        " \n",
        " Is equivalent to : \n",
        " \n",
        " \"What is the probability of observing both $x$ and $z$ ?\"  -->\n",
        "\n",
        "We can rewrite this to link both marginals with the joint one :\n",
        "\n",
        "$$\n",
        "p(x) = \\frac{p(z) * p(x|z)}{p(z|x)}\n",
        "$$\n",
        "\n",
        "Now the most important point in BM, is that we apply such reasoning to our model and its assumptions. In other words we are asking the question :\n",
        "\n",
        "> What is the probability of observing some data from my model, given it has some specified parameters $\\vec{\\mathbf{\\theta}}$. \n",
        "\n",
        "### Simple example\n",
        "Let's say we have a RV : $X ~ \\mathcal{N(\\mu,\\sigma)}$. In the most common and simple cases, both parameters are fixed and known. However, we could think of a situation, when one or both of them are actually not. In such a case, our RV actually becomes parametrised and can be expressed in the following way : $p_X(x)\\equiv p_X(x|\\mu,\\sigma)$. The values we will draw from such an RV will be conditioned on the parameters, which need to be *specified*. \n",
        "\n",
        "### What about observed data ?\n",
        "Let's say now we have some observed data $\\{X_i\\}$. Having laid a general behaviour for our model in the previous paragraph, we can now turn to our data and ask ourselves the question :\n",
        "\n",
        "\"What are the chances of observing the sample $\\{X_i\\}$ conditioned to the parameters $\\vec{\\mathbf{\\theta}} = \\{\\mu, \\sigma\\}$ ?\"\n",
        "\n",
        "In other words we are looking at $p(\\{X_i\\}|\\mu,\\sigma)$.\n",
        "\n",
        "##\n",
        "\n",
        "### Posterior distribution\n",
        "\n",
        "The posterior distribution emerges once we have adapted the prior using the likelihood we measure with respect to observed data. This step is similar to a learning epoch in the training process of Deep Learning.\n",
        "\n",
        "### MCMC\n",
        "The method allows us to fine tune the posterior distribution, by sampling synthetic data out of the prior and adapting it to be more similar to the observed data at every new iteration. Markov Chains Monte Carlo is tool that allows us to do this.\n",
        "\n",
        "## Spatial Economic Activity\n",
        "\n",
        "After this brief review, we get in the specific details of our problem. How do we develop a downscaling model with this ?\n",
        "The idea is to embed a fine scale spatial econometrics model into this Bayesian framework. On the one hand informing a behaviour at the fine spatial scale, dictated by the econometrics model, and controling that this behaviour aligns with our prior knowledge and constraints, leveraging the formalism described earlier. This problem is relying on 2 main hierarchies itself. The spatial and sectorial. \n",
        "\n",
        "## Spatial and Sectorial Hierarchies\n",
        "::: {.columns}\n",
        "::: {.column}\n",
        "### Levels of Spatial Granularity\n",
        "![](imgs/spat_hierarchy_plot.png)\n",
        ":::\n",
        "::: {.column }\n",
        "### Levels of Economic Activity Classification\n",
        "![](imgs/sector_levels_plot.png)\n",
        ":::\n",
        "::: \n",
        "<!-- end columns -->\n",
        "\n",
        "\n",
        "## Econometrics modelling\n",
        "\n",
        "We use a simplified linear model, inspired by (spatial) econometrics, to *inform* the bayesian method on how we expect our predictor variables to be linked to the industry level output. We apply this model to every location that has some non-zero predictor variable.  \n",
        "\n",
        "$$\n",
        "\\mu_{S_i} = \\sum_m \\alpha_m * x_m\n",
        "$$\n",
        "\n",
        "where $\\alpha_m$ are learned parameters and $x_m$ are the proxy variables that we assign to the relevant sectors. The result is a multilinear model, where some variables where masked, based on reasonable assumptions on their impact on a particular output, this steps refers to the *expert knowledge* that Bayesian methods rely on. Additionally, selecting only most relevant variables for each output helps reduce the dimensionality of the problem, which poses great challenges in the context of often lacking data to validate or inform the model.\n",
        "\n",
        "\n",
        "The linear model in turn yields a value $\\mu_{S_i}$ for a specific sector, which is interpreted as a mean value for a secor in a location by the Bayesian method and is combined with an uncertainty metric $\\sigma$ measured before hand as the average availability of data in the system. The tuple of values $(\\mu_{S_i}, \\sigma)$, with $\\sigma$ fixed and $\\mu_{S_i}$ which is obtained from the sampled linear combination of the $\\alpha$ parameters. \n",
        "\n",
        "## All together\n",
        "\n",
        "::: {.columns}\n",
        "::: {.column}\n"
      ],
      "id": "2ba0a47d"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "    with pm.Model() as model:\n",
        "\n",
        "        W = pm.Normal(\"W\", mu=mu, sigma=3, shape=(n_sectors, n_proxies))\n",
        "        W_masked = pm.Deterministic(\"W_masked\",W * w_mask)\n",
        "        X_ = pm.Data(\"X\", X)\n",
        "        \n",
        "        mu_pred = pm.Deterministic(\n",
        "            \"mu_pred\", \n",
        "            X_ @ W_masked.T,\n",
        "        )\n",
        "        y = pm.LogNormal(\n",
        "            \"y\", \n",
        "            mu=mu_pred, \n",
        "            sigma=std,\n",
        "            shape=(n_locations, n_sectors),\n",
        "        )\n",
        "        # Matrix multiplication to aggregate to region-sector\n",
        "        R_shared = pm.Data(\"R\", R)\n",
        "        G_shared = pm.Data(\"G\", G)\n",
        "        # spatial aggregation\n",
        "        y_region_sector = pm.Deterministic(\"y_region_sector\", R_shared @ y)\n",
        "        # sectoril aggregation\n",
        "        y_region_industry = pm.Deterministic(\"y_region_industry\", y_region_sector @ G_shared.T)\n",
        "        if entropy:\n",
        "            eps = 1e-10\n",
        "            y_soft = y / y.sum()\n",
        "            entropy_ = - pm.math.sum(\n",
        "                y_soft * pm.math.log(y_soft + eps), \n",
        "                # axis=1,\n",
        "                axis=None,\n",
        "            )\n",
        "            entropy = pm.Deterministic(\"entropy_\", entropy_)\n",
        "            pm.Potential(\"entropy\", var = alpha*entropy)\n",
        "            \n",
        "        Y_obs = pm.Normal(\n",
        "            \"Y_obs\",\n",
        "            mu=y_region_industry,\n",
        "            sigma=region_sector_totals*region_sector_totals_uncert, # eps \n",
        "            observed=region_sector_totals,\n",
        "        )\n",
        "\n",
        "        trace = pm.sample(\n",
        "            samples, \n",
        "            tune=tunes, \n",
        "            target_accept=target_accept,\n",
        "            max_treedepth=max_treedepth,\n",
        "            cores=n_cores,\n",
        "            chains=chains,\n",
        "        )\n"
      ],
      "id": "bcc8b681",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":::\n",
        "\n",
        "::: {.column}\n",
        "\n",
        "![](imgs/NGA.20_1_model_graph.png)\n",
        "\n",
        ":::\n",
        "::: <!-- end columns -->\n",
        "\n",
        "\n",
        "\n",
        "## Data \n",
        "\n",
        "### input\n",
        "\n",
        "- pois\n",
        "- nres\n",
        "- DOSE-WDI\n",
        "- Copernicus\n",
        "- GHSL pop\n",
        "\n",
        "\n",
        "- bea\n",
        "- ilostat\n",
        "- UK Value added\n",
        "- EU IO tables\n",
        "\n",
        "### Validation\n",
        "\n",
        "- Kummu\n",
        "- Bea\n",
        "- EU IO\n",
        "- Null model (OLD)\n",
        "\n",
        "## Catalogue \n",
        "\n",
        "### subsectors \n",
        "\n",
        "- GEM\n",
        "- CGFI\n",
        "- Climatrace\n",
        "- Edgar\n",
        "- MAPSPAM\n",
        "\n",
        "## All together \n"
      ],
      "id": "7de3bf1f"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/cenv1069/micromamba/envs/global-data-2/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}