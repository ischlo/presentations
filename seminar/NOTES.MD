
## Where we left off



## Next steps

Ex with human heights ?

MCMC paragraph

Table review and slide ameliorate


## BHM theory

- Inverse Problem Theory and Methods for Model Parameter 


(a) randomness is induced by known variability and (b) randomness is induced by variability that is itself unknown. 
* Dvorzak, M., Magnien, J., Kleb, U., Kraker, E., MÃ¼cke, M., 2022. Bayesian Hierarchical Modelling for Uncertainty Quantification in Operational Thermal Resistance of LED Systems. Applied Sciences 12, 10063. https://doi.org/10.3390/app121910063

"Everything can be everywhere with a certain probability"

High correlations between predictor variables at low resolutions -> bad

- downscaling : Under-constrained inverse problems

- Bayesian vs Frequentist


\pi - prior on the parameter

Practical thing : define the prior in a way to make sure it does not turn to 0 in potentially observable values. This is more important than defining it to be be close to the 'actual' value.


$$
p(x,y) = p(x)p(y|x) = p(y)p(x|y)
$$


From : https://pmarchand1.github.io/ECL8202/notes_cours/08-Intro_Bayes.html#introduction

Selon lâ€™interprÃ©tation frÃ©quentiste, les probabilitÃ©s reprÃ©sent la frÃ©quence dâ€™Ã©vÃ©nements aprÃ¨s un grand nombre de rÃ©pÃ©titions dâ€™une observation ou dâ€™une expÃ©rience. Dans ce cas-ci, nous pouvons assigner une probabilitÃ© Ã  ð‘€1 car le patient provient dâ€™une population et la maladie a une certaine frÃ©quence dans cette population.

Lâ€™interprÃ©tation frÃ©quentiste est Ã  la base de la plupart des cours dâ€™introduction aux statistiques, car elle permet notamment de dÃ©finir des tests dâ€™hypothÃ¨se et des intervalles de confiance. Dans cette approche, on peut associer une probabilitÃ© aux statistiques basÃ©es sur les donnÃ©es, comme la moyenne dâ€™un Ã©chantillon ð‘¥Â¯, mais pas aux paramÃ¨tres dâ€™un modÃ¨le comme la moyenne de la population ðœ‡. Quand on dÃ©finit un intervalle de confiance Ã  95% autour de ð‘¥Â¯, ce nâ€™est pas cet intervalle particulier qui a une probabilitÃ© de 95% de contenir ðœ‡ (aprÃ¨s lâ€™Ã©chantillonnage, lâ€™intervalle et ðœ‡ sont tous les deux fixes), mais câ€™est 95% des Ã©chantillons possibles de ð‘¥ qui produiraient un intervalle contenant la valeur de ðœ‡.

Selon lâ€™interprÃ©tation bayÃ©sienne, les probabilitÃ©s reprÃ©sentent notre incertitude sur la valeur dâ€™une quantitÃ©. On peut donc parler dâ€™une distribution de probabilitÃ© mÃªme pour une valeur prÃ©sumÃ©e fixe, ex.: un paramÃ¨tre dâ€™un modÃ¨le.

Historiquement, les dÃ©bats entre les deux approches ont souvent Ã©tÃ© acrimonieux. Aujourdâ€™hui, les mÃªmes statisticiens peuvent employer lâ€™approche frÃ©quentiste ou lâ€™approche bayÃ©sienne selon la nature du problÃ¨me. Cependant, il faut sâ€™assurer de toujours interprÃ©ter les rÃ©sultats en fonction de lâ€™approche utilisÃ©e. Il faut se rappeler, par exemple, quâ€™un intervalle de confiance frÃ©quentiste ne reprÃ©sente pas une distribution de probabilitÃ© du paramÃ¨tre, ou quâ€™une vÃ©rification de lâ€™ajustement dâ€™un modÃ¨le bayÃ©sien nâ€™est pas Ã©quivalente Ã  un test dâ€™hypothÃ¨se nulle.

Une des critiques courantes de lâ€™infÃ©rence bayÃ©sienne est que lâ€™assignation dâ€™une distribution a priori ajoute un biais Ã  lâ€™analyse. Cependant, si le choix de cette distribution est justifiÃ©e par le besoin de pÃ©naliser des valeurs trop extrÃªmes des paramÃ¨tres, le rÃ´le de la distribution a priori nâ€™est pas si diffÃ©rent de celui dâ€™un effet alÃ©atoire qui resserre les moyennes de groupes vers la moyenne gÃ©nÃ©rale, ou du paramÃ¨tre de lissage dans un modÃ¨le additif qui pÃ©nalise les courbes trop complexes. Toutes ces mÃ©thodes sont des exemples de **rÃ©gularisation**, câ€™est-Ã -dire lâ€™imposition de contraintes permettant de contrÃ´ler le risque de surajustement dans un modÃ¨le complexe, sans avoir Ã  fixer complÃ¨tement certains paramÃ¨tres et certains effets.

Puisque lâ€™infÃ©rence bayÃ©sienne sâ€™applique Ã  plusieurs types de modÃ¨les, les statistiques utilisÃ©es pour vÃ©rifier lâ€™ajustement varient dâ€™un modÃ¨le Ã  lâ€™autre. Cependant, une stratÃ©gie gÃ©nÃ©rale consiste Ã  simuler des jeux de donnÃ©es Ã  partir de la distribution a posteriori des paramÃ¨tres et vÃ©rifier si les caractÃ©ristiques des donnÃ©es observÃ©es sont bien reprÃ©sentÃ©es par ces simulations. Cette technique sâ€™appelle la vÃ©rification des prÃ©dictions a posteriori (ou posterior predictive check).


## Log normal prior

Motivation :
0 becomes unlikely as soon as there is something.
0 is highly likely when looking at the whole surface of earth.

Will have a mode in the relatively small values, but will also leave room for extreme values -> high concentration of productivity, say, in urban clusters.
This behaviour is well described by fat tailed distributions, such as log-normal.


Resources : 

- https://bayesball.github.io/BOOK/probability-a-measurement-of-uncertainty.html 
- https://bookdown.org/kevin_davisross/bayesian-reasoning-and-methods/prior.html
- https://bayesiancomputationbook.com/markdown/chp_01.html#conjugate-priors
- https://distribution-explorer.github.io/continuous/exponential.html
- https://www.pymc.io/projects/examples/en/latest/howto/model_builder.html#saving-model-to-file
- https://www.bayesrulesbook.com/chapter-5
- https://ourcodingclub.github.io/tutorials/brms/
- https://pmarchand1.github.io/ECL8202/notes_cours/08-Intro_Bayes.html#introduction
- https://paulbuerkner.com/brms/articles/brms_nonlinear.html
- https://python.arviz.org/en/stable/examples/plot_bpv_tstat.html


### Pros and Cons 
Of Bayesian (hierarchical) Modelling

- Pros :
    - Can handle complex data structures
    - Allows for uncertainty quantification
    - Can incorporate prior knowledge
    - Flexibility

- Cons :
    - Computationally intensive
    - Requires **careful** prior selection
    - Sensitive to model specification
    - Flexibility

- Bayesian is generally complex : Theory and formalism (Bayes, Monte Carlo, Information theory), software ecosystem (world of it's own), PPLs (Probabilistic Programming Languages)

- Data whose observations are considered to be exact in the scope of an analysis are termed hard data. In contrast, soft data represent observed data that might carry nontrivial uncertainty in the context of a study

## Intractability